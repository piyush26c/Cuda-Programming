{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-6(Vector addition + Matrix multiplication).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlc8YnfQHVMRQf4uvQQJy8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyush26c/Cuda-Programming/blob/main/Assignment_6(Vector_addition_%2B_Matrix_multiplication).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpGfeM31A1VS",
        "outputId": "71ea71fc-21ba-4cd9-99f2-a8ed6de9f9b1"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNxrpmEWCDOE",
        "outputId": "0727169b-e663-432d-ee6a-8954d21647c2"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-sw_5ycgg\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-sw_5ycgg\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=81a6998cec984dcd4a4c2ac61e8843d00e9777acac0dbbf74a9e17b4aed714d1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4tx0brkb/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEd-RF1DClzS",
        "outputId": "a55cd8d8-9da8-4e32-cfa9-e7602eb919c7"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqGLEIQVC_N8",
        "outputId": "230d4a8e-a69f-4a67-d8cd-069aeeaab8ab"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE 10\n",
        "\n",
        "__global__ void vectorAddition (long long *vectorA_, long long *vectorB_, long long *vectorC_) {\n",
        "\tvectorC_[blockIdx.x] = vectorA_[blockIdx.x] + vectorB_[blockIdx.x];\n",
        "}\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "\tlong long *hostVectorA, *hostVectorB, *hostVectorC;\n",
        "\tlong long *deviceVectorA, *deviceVectorB, *deviceVectorC;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A, B, C and insert input values\n",
        "  hostVectorA = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVectorA);\n",
        "  hostVectorB = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVectorB);\n",
        "  hostVectorC = (long long *)malloc(memorySize);\n",
        "\t\n",
        "\t// Allocate space for device vectors A, B, C\n",
        "  cudaMalloc((void **)&deviceVectorA, VECTOR_SIZE * sizeof(long long));\n",
        "  cudaMalloc((void **)&deviceVectorB, VECTOR_SIZE *sizeof(long long));\n",
        "  cudaMalloc((void **)&deviceVectorC, VECTOR_SIZE * sizeof(long long));\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "  cudaMemcpy(deviceVectorA, hostVectorA, VECTOR_SIZE * sizeof(long long), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceVectorB, hostVectorB, VECTOR_SIZE * sizeof(long long), cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t//by creating multiple blocks with single thread in it.\n",
        "  dim3 blocksPerGrid(VECTOR_SIZE, 1, 1);\n",
        "  dim3 threadsPerBlock(1, 1, 1);\n",
        "\tvectorAddition<<<blocksPerGrid, threadsPerBlock>>>(deviceVectorA, deviceVectorB, deviceVectorC);\n",
        " \n",
        "  // Copy result back to host\n",
        "  cudaMemcpy(hostVectorC, deviceVectorC, VECTOR_SIZE * sizeof(long long), cudaMemcpyDeviceToHost);\n",
        " \n",
        "  printf(\"Program : Vector Addition (Parallel Programming)\\n\");\n",
        "  printf(\"VECTOR A : \");\n",
        "\tprintVector(hostVectorA);\n",
        "\tprintf(\"\\nVECTOR B : \");\n",
        "\tprintVector(hostVectorB);\n",
        "\tprintf(\"\\nVECTOR C : \");\n",
        "\tprintVector(hostVectorC);\n",
        "  free(hostVectorA); \n",
        "\tfree(hostVectorB); \n",
        "\tfree(hostVectorC);\n",
        " \n",
        "  // free gpu memory\n",
        "  cudaFree(deviceVectorA); \n",
        "\tcudaFree(deviceVectorB); \n",
        "\tcudaFree(deviceVectorC);\n",
        "\t\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Program : Vector Addition (Parallel Programming)\n",
            "VECTOR A : 0 1 2 3 4 5 6 7 8 9 \n",
            "VECTOR B : 0 1 2 3 4 5 6 7 8 9 \n",
            "VECTOR C : 0 2 4 6 8 10 12 14 16 18 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yhHwvzYUJdl",
        "outputId": "3bc1fb7e-0cbd-45c8-d0e3-e34a5fe27c53"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE (1 << (VECTOR_SIZE_))   //corresponds to 2^VECTOR_SIZE_\n",
        "#define VECTOR_SIZE_ 3\n",
        "\n",
        "__global__ void vectorAddition (long long *vectorA_, long long *vectorB_, long long *vectorC_) {\n",
        "\tvectorC_[blockIdx.x] = vectorA_[blockIdx.x] + vectorB_[blockIdx.x];\n",
        "}\n",
        "\n",
        "__global__ void vectorMatrixMultiplication (long long *vectorA_, long long *vectorB_, long long *vectorC_) {\n",
        "\t  int row = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "    int col = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\n",
        "    float tmpSum = 0;\n",
        "\n",
        "    if (row < VECTOR_SIZE && col < VECTOR_SIZE) {\n",
        "        // each thread computes one element of the block sub-matrix\n",
        "        for (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "            tmpSum += vectorA_[row * VECTOR_SIZE + indx] * vectorB_[indx * VECTOR_SIZE + col];\n",
        "        }\n",
        "    }\n",
        "    vectorC_[row * VECTOR_SIZE + col] = tmpSum;\n",
        "}\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void fillMatrixVector (long long *vector_) {\n",
        "\tfor (int indx1 = 0; indx1 < VECTOR_SIZE; indx1++) {\n",
        "\t\tfor (int indx2 = 0; indx2 < VECTOR_SIZE; indx2++) {\n",
        "\t\t\tvector_[indx1 * VECTOR_SIZE + indx2] = 1;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printMatrixVector (long long *vector_) {\n",
        "\tfor (int indx1 = 0; indx1 < VECTOR_SIZE; indx1++) {\n",
        "\t\tfor (int indx2 = 0; indx2 < VECTOR_SIZE; indx2++) {\n",
        "\t\t\tprintf(\"%lld \", vector_[indx1 * VECTOR_SIZE + indx2]);\n",
        "\t\t}\n",
        "    printf(\"\\n\");\n",
        "\t}\n",
        "}\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "\t//program for vector addition\n",
        "\tlong long *hostVectorA, *hostVectorB, *hostVectorC;\n",
        "\tlong long *deviceVectorA, *deviceVectorB, *deviceVectorC;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A, B, C and insert input values\n",
        "  hostVectorA = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVectorA);\n",
        "  hostVectorB = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVectorB);\n",
        "  hostVectorC = (long long *)malloc(memorySize);\n",
        "\t\n",
        "\t// Allocate space for device vectors A, B, C\n",
        "  cudaMalloc((void **)&deviceVectorA, memorySize);\n",
        "  cudaMalloc((void **)&deviceVectorB, memorySize);\n",
        "  cudaMalloc((void **)&deviceVectorC, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "  cudaMemcpy(deviceVectorA, hostVectorA, memorySize, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceVectorB, hostVectorB, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t//by creating multiple blocks with single thread in it.\n",
        "\tdim3 blocksPerGrid(VECTOR_SIZE, 1, 1);\n",
        "\tdim3 threadsPerBlock(1, 1, 1);\n",
        "\tvectorAddition<<<blocksPerGrid, threadsPerBlock>>>(deviceVectorA, deviceVectorB, deviceVectorC);\n",
        " \n",
        "  // Copy result back to host\n",
        "  cudaMemcpy(hostVectorC, deviceVectorC, memorySize, cudaMemcpyDeviceToHost);\n",
        "  printf(\"\\n\\nVector Addition (Parallel Programming) : \");\n",
        "  printf(\"\\nVECTOR A : \");\n",
        "\tprintVector(hostVectorA);\n",
        "\tprintf(\"\\nVECTOR B : \");\n",
        "\tprintVector(hostVectorB);\n",
        "\tprintf(\"\\nVECTOR C : \");\n",
        "\tprintVector(hostVectorC);\n",
        "  free(hostVectorA); \n",
        "\tfree(hostVectorB); \n",
        "\tfree(hostVectorC);\n",
        " \n",
        "  //free gpu memory\n",
        "  cudaFree(deviceVectorA); \n",
        "\tcudaFree(deviceVectorB); \n",
        "\tcudaFree(deviceVectorC);\n",
        "\t\n",
        "  {\n",
        "  //matrix multiplication scope starts\n",
        "\t//program for matrix multiplication\n",
        "\tlong long *hostMatrixA, *hostMatrixB, *hostMatrixC;\n",
        "\tlong long *deviceMatrixA, *deviceMatrixB, *deviceMatrixC;\n",
        "\t//allocate 2-D space\n",
        "\tlong long memoryMatrixSize = VECTOR_SIZE * VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host matrix vectors A, B, C and insert input values\n",
        "  hostMatrixA = (long long *)malloc(memoryMatrixSize); \n",
        "\tfillMatrixVector(hostMatrixA);\n",
        "  hostMatrixB = (long long *)malloc(memoryMatrixSize); \n",
        "\tfillMatrixVector(hostMatrixB);\n",
        "  hostMatrixC = (long long *)malloc(memoryMatrixSize);\n",
        "\t\n",
        "\t// Allocate space for device matrix vectors A, B, C\n",
        "  cudaMalloc((void **)&deviceMatrixA, memoryMatrixSize);\n",
        "  cudaMalloc((void **)&deviceMatrixB, memoryMatrixSize);\n",
        "  cudaMalloc((void **)&deviceMatrixC, memoryMatrixSize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "  cudaMemcpy(deviceMatrixA, hostMatrixA, memoryMatrixSize, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceMatrixB, hostMatrixB, memoryMatrixSize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t//by creating multiple blocks with single thread in it.\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE, VECTOR_SIZE, 1);\n",
        "\t \n",
        "\tif (VECTOR_SIZE * VECTOR_SIZE > 512){\t\t\n",
        "\t\t    threadsPerBlock.x = 512;\n",
        "        threadsPerBlock.y = 512;\n",
        "        blocksPerGrid.x = ceil(double(VECTOR_SIZE)/double(threadsPerBlock.x));\n",
        "        blocksPerGrid.y = ceil(double(VECTOR_SIZE)/double(threadsPerBlock.y));\n",
        "    }\n",
        "\t\t\n",
        "\tvectorMatrixMultiplication<<<blocksPerGrid, threadsPerBlock>>>(deviceMatrixA, deviceMatrixB, deviceMatrixC);\n",
        "\t\n",
        "\t// Copy result back to host\n",
        "  cudaMemcpy(hostMatrixC, deviceMatrixC, memoryMatrixSize, cudaMemcpyDeviceToHost);\n",
        "  printf(\"\\n\\nMatrix Multiplication (Parallel Programming) : \");\n",
        "  printf(\"\\nMATRIX VECTOR A : \\n\");\n",
        "\tprintMatrixVector(hostMatrixA);\n",
        "\tprintf(\"\\nMATRIX VECTOR B : \\n\");\n",
        "\tprintMatrixVector(hostMatrixB);\n",
        "\tprintf(\"\\nMATRIX VECTOR C : \\n\");\n",
        "\tprintMatrixVector(hostMatrixC);\n",
        "  free(hostMatrixA); \n",
        "\tfree(hostMatrixB); \n",
        "\tfree(hostMatrixC);\n",
        " \n",
        "  //free gpu memory\n",
        "  cudaFree(deviceMatrixA); \n",
        "\tcudaFree(deviceMatrixB); \n",
        "\tcudaFree(deviceMatrixC);\n",
        "\t}//matrix multiplication scope ends\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Vector Addition (Parallel Programming) : \n",
            "VECTOR A : 0 1 2 3 4 5 6 7 \n",
            "VECTOR B : 0 1 2 3 4 5 6 7 \n",
            "VECTOR C : 0 2 4 6 8 10 12 14 \n",
            "\n",
            "Matrix Multiplication (Parallel Programming) : \n",
            "MATRIX VECTOR A : \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "\n",
            "MATRIX VECTOR B : \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "1 1 1 1 1 1 1 1 \n",
            "\n",
            "MATRIX VECTOR C : \n",
            "8 8 8 8 8 8 8 8 \n",
            "8 8 8 8 8 8 8 8 \n",
            "8 8 8 8 8 8 8 8 \n",
            "8 8 8 8 8 8 8 8 \n",
            "8 8 8 8 8 8 8 8 \n",
            "8 8 8 8 8 8 8 8 \n",
            "8 8 8 8 8 8 8 8 \n",
            "8 8 8 8 8 8 8 8 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}