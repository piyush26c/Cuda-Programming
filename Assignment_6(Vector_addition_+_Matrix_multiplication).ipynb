{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-6(Vector addition + Matrix multiplication).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkmEKophOo+N5+kH8CZ9IT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyush26c/Cuda-Programming/blob/main/Assignment_6(Vector_addition_%2B_Matrix_multiplication).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpGfeM31A1VS",
        "outputId": "e9bd3d1c-d6a6-4612-e782-6e4092162eab"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNxrpmEWCDOE",
        "outputId": "ab6afa7e-0cd6-4a08-93b5-9f72950db469"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-0n3xor96\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-0n3xor96\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=df6337fbf5669d1dfe91b7f18ad31c2a21b8a4820ad7abe324d8dccf9802375c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fup50q8l/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEd-RF1DClzS",
        "outputId": "a9f9b87b-f400-4145-d5e4-4f4df77eb76c"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqGLEIQVC_N8",
        "outputId": "8c003ebd-d459-479c-e6ee-14da50ce9d4c"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE 10\n",
        "\n",
        "__global__ void vectorAddition (long long *vectorA_, long long *vectorB_, long long *vectorC_) {\n",
        "\tvectorC_[blockIdx.x] = vectorA_[blockIdx.x] + vectorB_[blockIdx.x];\n",
        "}\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "\tlong long *hostVectorA, *hostVectorB, *hostVectorC;\n",
        "\tlong long *deviceVectorA, *deviceVectorB, *deviceVectorC;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A, B, C and insert input values\n",
        "  hostVectorA = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVectorA);\n",
        "  hostVectorB = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVectorB);\n",
        "  hostVectorC = (long long *)malloc(memorySize);\n",
        "\t\n",
        "\t// Allocate space for device vectors A, B, C\n",
        "  cudaMalloc((void **)&deviceVectorA, VECTOR_SIZE * sizeof(long long));\n",
        "  cudaMalloc((void **)&deviceVectorB, VECTOR_SIZE *sizeof(long long));\n",
        "  cudaMalloc((void **)&deviceVectorC, VECTOR_SIZE * sizeof(long long));\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "  cudaMemcpy(deviceVectorA, hostVectorA, VECTOR_SIZE * sizeof(long long), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceVectorB, hostVectorB, VECTOR_SIZE * sizeof(long long), cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t//by creating multiple blocks with single thread in it.\n",
        "  dim3 blocksPerGrid(VECTOR_SIZE, 1, 1);\n",
        "  dim3 threadsPerBlock(1, 1, 1);\n",
        "\tvectorAddition<<<blocksPerGrid, threadsPerBlock>>>(deviceVectorA, deviceVectorB, deviceVectorC);\n",
        " \n",
        "  // Copy result back to host\n",
        "  cudaMemcpy(hostVectorC, deviceVectorC, VECTOR_SIZE * sizeof(long long), cudaMemcpyDeviceToHost);\n",
        " \n",
        "  printf(\"Program : Vector Addition (Parallel Programming)\\n\");\n",
        "  printf(\"VECTOR A : \");\n",
        "\tprintVector(hostVectorA);\n",
        "\tprintf(\"\\nVECTOR B : \");\n",
        "\tprintVector(hostVectorB);\n",
        "\tprintf(\"\\nVECTOR C : \");\n",
        "\tprintVector(hostVectorC);\n",
        "  free(hostVectorA); \n",
        "\tfree(hostVectorB); \n",
        "\tfree(hostVectorC);\n",
        " \n",
        "  // free gpu memory\n",
        "  cudaFree(deviceVectorA); \n",
        "\tcudaFree(deviceVectorB); \n",
        "\tcudaFree(deviceVectorC);\n",
        "\t\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Program : Vector Addition (Parallel Programming)\n",
            "VECTOR A : 0 1 2 3 4 5 6 7 8 9 \n",
            "VECTOR B : 0 1 2 3 4 5 6 7 8 9 \n",
            "VECTOR C : 0 2 4 6 8 10 12 14 16 18 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yhHwvzYUJdl",
        "outputId": "4f88f3ae-f48b-4426-cac1-a709c03b0e0d"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE 10\n",
        "\n",
        "__global__ void vectorAddition (long long *vectorA_, long long *vectorB_, long long *vectorC_) {\n",
        "\tvectorC_[blockIdx.x] = vectorA_[blockIdx.x] + vectorB_[blockIdx.x];\n",
        "}\n",
        "\n",
        "__global__ void vectorMatrixMultiplication (long long *vectorA_, long long *vectorB_, long long *vectorC_) {\n",
        "\tint row = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "    int col = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\n",
        "    float tmpSum = 0;\n",
        "\n",
        "    if (row < VECTOR_SIZE && col < VECTOR_SIZE) {\n",
        "        // each thread computes one element of the block sub-matrix\n",
        "        for (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "            tmpSum += vectorA_[row * VECTOR_SIZE + indx] * vectorB_[indx * VECTOR_SIZE + col];\n",
        "        }\n",
        "    }\n",
        "    vectorC_[row * VECTOR_SIZE + col] = tmpSum;\n",
        "}\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void fillMatrixVector (long long *vector_) {\n",
        "\tfor (int indx1 = 0; indx1 < VECTOR_SIZE; indx1++) {\n",
        "\t\tfor (int indx2 = 0; indx2 < VECTOR_SIZE; indx2++) {\n",
        "\t\t\tvector_[indx1 * VECTOR_SIZE + indx2] = 1;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "\t//program for vector addition\n",
        "\tlong long *hostVectorA, *hostVectorB, *hostVectorC;\n",
        "\tlong long *deviceVectorA, *deviceVectorB, *deviceVectorC;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A, B, C and insert input values\n",
        "  hostVectorA = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVectorA);\n",
        "  hostVectorB = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVectorB);\n",
        "  hostVectorC = (long long *)malloc(memorySize);\n",
        "\t\n",
        "\t// Allocate space for device vectors A, B, C\n",
        "  cudaMalloc((void **)&deviceVectorA, memorySize);\n",
        "  cudaMalloc((void **)&deviceVectorB, memorySize);\n",
        "  cudaMalloc((void **)&deviceVectorC, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "  cudaMemcpy(deviceVectorA, hostVectorA, memorySize, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceVectorB, hostVectorB, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t//by creating multiple blocks with single thread in it.\n",
        "\tdim3 blocksPerGrid(VECTOR_SIZE, 1, 1);\n",
        "\tdim3 threadsPerBlock(1, 1, 1);\n",
        "\tvectorAddition<<<blocksPerGrid, threadsPerBlock>>>(deviceVectorA, deviceVectorB, deviceVectorC);\n",
        " \n",
        "  // Copy result back to host\n",
        "  cudaMemcpy(hostVectorC, deviceVectorC, memorySize, cudaMemcpyDeviceToHost);\n",
        "  printf(\"\\n\\nVector Addition (Parallel Programming) : \");\n",
        "  printf(\"\\nVECTOR A : \");\n",
        "\tprintVector(hostVectorA);\n",
        "\tprintf(\"\\nVECTOR B : \");\n",
        "\tprintVector(hostVectorB);\n",
        "\tprintf(\"\\nVECTOR C : \");\n",
        "\tprintVector(hostVectorC);\n",
        "  free(hostVectorA); \n",
        "\tfree(hostVectorB); \n",
        "\tfree(hostVectorC);\n",
        " \n",
        "  //free gpu memory\n",
        "  cudaFree(deviceVectorA); \n",
        "\tcudaFree(deviceVectorB); \n",
        "\tcudaFree(deviceVectorC);\n",
        "\t{//matrix multiplication scope starts\n",
        "\t//program for matrix multiplication\n",
        "\tlong long *hostMatrixA, *hostMatrixB, *hostMatrixC;\n",
        "\tlong long *deviceMatrixA, *deviceMatrixB, *deviceMatrixC;\n",
        "\t//allocate 2-D space\n",
        "\tlong long memoryMatrixSize = VECTOR_SIZE * VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host matrix vectors A, B, C and insert input values\n",
        "  hostMatrixA = (long long *)malloc(memoryMatrixSize); \n",
        "\tfillMatrixVector(hostMatrixA);\n",
        "  hostMatrixB = (long long *)malloc(memoryMatrixSize); \n",
        "\tfillMatrixVector(hostMatrixB);\n",
        "  hostMatrixC = (long long *)malloc(memoryMatrixSize);\n",
        "\t\n",
        "\t// Allocate space for device matrix vectors A, B, C\n",
        "  cudaMalloc((void **)&deviceMatrixA, memoryMatrixSize);\n",
        "  cudaMalloc((void **)&deviceMatrixB, memoryMatrixSize);\n",
        "  cudaMalloc((void **)&deviceMatrixC, memoryMatrixSize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "  cudaMemcpy(deviceMatrixA, hostMatrixA, memoryMatrixSize, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceMatrixB, hostMatrixB, memoryMatrixSize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t//by creating multiple blocks with single thread in it.\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE, VECTOR_SIZE, 1);\n",
        "\tif (VECTOR_SIZE * VECTOR_SIZE > 512){\t\t\n",
        "\t\t    threadsPerBlock.x = 512;\n",
        "        threadsPerBlock.y = 512;\n",
        "        blocksPerGrid.x = ceil(double(VECTOR_SIZE)/double(threadsPerBlock.x));\n",
        "        blocksPerGrid.y = ceil(double(VECTOR_SIZE)/double(threadsPerBlock.y));\n",
        "    }\n",
        "\tvectorMatrixMultiplication<<<blocksPerGrid, threadsPerBlock>>>(deviceMatrixA, deviceMatrixB, deviceMatrixC);\n",
        "\t\n",
        "\t// Copy result back to host\n",
        "  cudaMemcpy(hostMatrixC, deviceMatrixC, memoryMatrixSize, cudaMemcpyDeviceToHost);\n",
        "  printf(\"\\n\\nMatrix Multiplication (Parallel Programming) : \");\n",
        "  printf(\"\\nMATRIX VECTOR A : \");\n",
        "\tprintVector(hostMatrixA);\n",
        "\tprintf(\"\\nMATRIX VECTOR B : \");\n",
        "\tprintVector(hostMatrixB);\n",
        "\tprintf(\"\\nMATRIX VECTOR C : \");\n",
        "\tprintVector(hostMatrixC);\n",
        "  free(hostMatrixA); \n",
        "\tfree(hostMatrixB); \n",
        "\tfree(hostMatrixC);\n",
        " \n",
        "  //free gpu memory\n",
        "  cudaFree(deviceMatrixA); \n",
        "\tcudaFree(deviceMatrixB); \n",
        "\tcudaFree(deviceMatrixC);\n",
        "\t}//matrix multiplication scope ends\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Vector Addition (Parallel Programming) : \n",
            "VECTOR A : 0 1 2 3 4 5 6 7 8 9 \n",
            "VECTOR B : 0 1 2 3 4 5 6 7 8 9 \n",
            "VECTOR C : 0 2 4 6 8 10 12 14 16 18 \n",
            "\n",
            "Matrix Multiplication (Parallel Programming) : \n",
            "MATRIX VECTOR A : 1 1 1 1 1 1 1 1 1 1 \n",
            "MATRIX VECTOR B : 1 1 1 1 1 1 1 1 1 1 \n",
            "MATRIX VECTOR C : 10 10 10 10 10 10 10 10 10 10 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}