{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_5_MinElem_MaxElem_Mean_StandardDeviation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgjBJBj+RyTRlFYqsoQIHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyush26c/Cuda-Programming/blob/main/Assignment_5_MinElem_MaxElem_Mean_StandardDeviation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrZKPSecYiOg",
        "outputId": "a45b247d-144d-43c2-fa42-ee19e50d7d4c"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkyNTwMrdO3j",
        "outputId": "974175e8-ed91-470d-d37c-4e7059e9cd42"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-wb6by2f4\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-wb6by2f4\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=bf41d45b6f331861ce0e90ffac6bf09e37658fa145baface6a1467c97996c5f3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xu6zzdkw/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_itzKwpf1fl",
        "outputId": "3867105c-322e-49df-b92a-6fe0e903ca86"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oErlNoRQ6A1C",
        "outputId": "cb962d8f-f97a-418c-cad0-3f84a8bbca8f"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE 10\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx ;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMinElem (long long *vector_) {\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] > vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main (void) {\n",
        "\t//program for finding minimum element from input vector\n",
        "\tlong long *hostVector, resultMinElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMinElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMinElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\tprintf(\"\\nFinding the Minimum Element (Parallel Programming) \");\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe minimum element in given vector : %lld\", resultMinElem);\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finding the Minimum Element (Parallel Programming) \n",
            "Input Vector : 0 1 2 3 4 5 6 7 8 9 \n",
            "The minimum element in given vector : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLYs--VB4Es2",
        "outputId": "017b646c-e75e-451a-db14-6049a7fd98d7"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE (1 << (VECTOR_SIZE_))   //corresponds to 2 ^VECTOR_SIZE_\n",
        "#define VECTOR_SIZE_ 5\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMinElem (long long *vector_) {\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] > vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMaxElem (long long *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] < vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\t\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main (void) {\n",
        "\t{\n",
        "\t//program for finding minimum element from input vector\n",
        "\tlong long *hostVector, resultMinElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMinElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMinElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe minimum element in given vector : %lld\", resultMinElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding maximum element from input vector\n",
        "\n",
        "\tlong long *hostVector, resultMaxElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMaxElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMaxElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tprintf(\"\\nThe maximum element in given vector : %lld\", resultMaxElem);\n",
        "\t}\n",
        "\t\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Vector : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \n",
            "The minimum element in given vector : 1\n",
            "The maximum element in given vector : 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uIV3zHp9ONS",
        "outputId": "42a6c91e-46d0-42aa-f8ac-d9da4a5056f8"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE (1 << (VECTOR_SIZE_))   //corresponds to 2 ^VECTOR_SIZE_\n",
        "#define VECTOR_SIZE_ 3\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void fillVectorWDV (double *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = (double) indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMinElem (long long *vector_) {\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] > vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMaxElem (long long *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] < vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\t\n",
        "}\n",
        "\n",
        "__global__ void findMean (double *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tvector_[firstElemIndx] += vector_[secondElemIndx];\t\t\t\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "\tvector_[0] = vector_[0] / (double) VECTOR_SIZE;\n",
        "}\n",
        "\n",
        "\n",
        "int main (void) {\n",
        "\t{\n",
        "\t//program for finding minimum element from input vector\n",
        "\tlong long *hostVector, resultMinElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMinElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMinElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe minimum element in given vector : %lld\", resultMinElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding maximum element from input vector\n",
        "\n",
        "\tlong long *hostVector, resultMaxElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMaxElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMaxElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe maximum element in given vector : %lld\", resultMaxElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding mean from input vector\n",
        "\n",
        "\tdouble *hostVector;\n",
        "\tdouble resultMean;\n",
        "\tdouble *deviceVector;\n",
        "\tdouble memorySize = VECTOR_SIZE * sizeof(double);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (double *)malloc(memorySize); \n",
        "\tfillVectorWDV(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMean<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMean, deviceVector, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nThe mean of the given vector : %lf\", resultMean);\n",
        "\t}\n",
        "\t\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Vector : 1 2 3 4 5 6 7 8 \n",
            "The minimum element in given vector : 1\n",
            "Input Vector : 1 2 3 4 5 6 7 8 \n",
            "The maximum element in given vector : 8\n",
            "The mean of the given vector : 4.500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2460Sp45B0Ky",
        "outputId": "aa27afc3-04eb-48c3-9093-99178aaae7a6"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE (1 << (VECTOR_SIZE_))   //corresponds to 2 ^VECTOR_SIZE_\n",
        "#define VECTOR_SIZE_ 3\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void fillVectorWDV (double *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = (double) indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMinElem (long long *vector_) {\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] > vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMaxElem (long long *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] < vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\t\n",
        "}\n",
        "\n",
        "__global__ void findMean (double *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tvector_[firstElemIndx] += vector_[secondElemIndx];\t\t\t\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "\tvector_[0] = vector_[0] / (double) VECTOR_SIZE;\n",
        "}\n",
        "\n",
        "__global__ void findSum (long long *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tvector_[firstElemIndx] += vector_[secondElemIndx];\t\t\t\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main (void) {\n",
        "\t{\n",
        "\t//program for finding minimum element from input vector\n",
        "\tlong long *hostVector, resultMinElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMinElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMinElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe minimum element in given vector : %lld\", resultMinElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding maximum element from input vector\n",
        "\n",
        "\tlong long *hostVector, resultMaxElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMaxElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMaxElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe maximum element in given vector : %lld\", resultMaxElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding mean from input vector\n",
        "\n",
        "\tdouble *hostVector;\n",
        "\tdouble resultMean;\n",
        "\tdouble *deviceVector;\n",
        "\tdouble memorySize = VECTOR_SIZE * sizeof(double);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (double *)malloc(memorySize); \n",
        "\tfillVectorWDV(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMean<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMean, deviceVector, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nThe mean of the given vector : %lf\", resultMean);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding sum of all elements from input vector\n",
        "\n",
        "\tlong long *hostVector, resultSum;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindSum<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultSum, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tprintf(\"\\nThe summation of all the elements in given vector : %lld\", resultSum);\n",
        "\t}\n",
        "\t\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Vector : 1 2 3 4 5 6 7 8 \n",
            "The minimum element in given vector : 1\n",
            "Input Vector : 1 2 3 4 5 6 7 8 \n",
            "The maximum element in given vector : 8\n",
            "The mean of the given vector : 4.500000\n",
            "The summation of all the elements in given vector : 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKDI6VxiDz0R",
        "outputId": "210abbff-5559-4f4b-d749-7020ebe5b10c"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#define VECTOR_SIZE (1 << (VECTOR_SIZE_))   //corresponds to 2 ^VECTOR_SIZE_\n",
        "#define VECTOR_SIZE_ 5\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void fillVectorWDV (double *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = (double) indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMinElem (long long *vector_) {\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] > vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMaxElem (long long *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] < vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\t\n",
        "}\n",
        "\n",
        "__global__ void findMean (double *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tvector_[firstElemIndx] += vector_[secondElemIndx];\t\t\t\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "\tvector_[0] = vector_[0] / (double) VECTOR_SIZE;\n",
        "}\n",
        "\n",
        "__global__ void findSum (long long *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tvector_[firstElemIndx] += vector_[secondElemIndx];\t\t\t\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main (void) {\n",
        "\t{\n",
        "\t//program for finding minimum element from input vector\n",
        "\tlong long *hostVector, resultMinElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMinElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMinElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe minimum element in given vector : %lld\", resultMinElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding maximum element from input vector\n",
        "\n",
        "\tlong long *hostVector, resultMaxElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMaxElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMaxElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe maximum element in given vector : %lld\", resultMaxElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding mean from input vector\n",
        "\n",
        "\tdouble *hostVector;\n",
        "\tdouble resultMean;\n",
        "\tdouble *deviceVector;\n",
        "\tdouble memorySize = VECTOR_SIZE * sizeof(double);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (double *)malloc(memorySize); \n",
        "\tfillVectorWDV(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMean<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMean, deviceVector, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nThe mean of the given vector : %lf\", resultMean);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding sum of all elements from input vector\n",
        "\n",
        "\tlong long *hostVector, resultSum;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindSum<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultSum, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nThe summation of all the elements in given vector : %lld\", resultSum);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding variance of elements from input vector\n",
        "\t//first find mean and then substract it from each element parallelly\n",
        "\n",
        "\tlong long *hostVector, resultSum;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\tdouble mean;\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindSum<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultSum, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tmean = resultSum / (double) VECTOR_SIZE;\n",
        "\t\n",
        "\tprintf(\"\\nThe summation of all the elements in given vector : %lld, %lf\", resultSum, mean);\n",
        "\t}\n",
        "\t\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Vector : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \n",
            "The minimum element in given vector : 1\n",
            "Input Vector : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \n",
            "The maximum element in given vector : 32\n",
            "The mean of the given vector : 16.500000\n",
            "The summation of all the elements in given vector : 528\n",
            "The summation of all the elements in given vector : 528, 16.500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmCFWTmzIaIp",
        "outputId": "d0b9adf0-26f1-41c7-b173-20bf5a3b0e12"
      },
      "source": [
        "%%cu\n",
        "//Author : Piyush Rajendra Chaudhari\n",
        "//Roll No: BECOC311\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <math.h>\n",
        "#define VECTOR_SIZE (1 << (VECTOR_SIZE_))   //corresponds to 2 ^VECTOR_SIZE_\n",
        "#define VECTOR_SIZE_ 3\n",
        "\n",
        "void fillVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void fillVectorWDV (double *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tvector_[indx] = (double) indx + 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVector (long long *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lld \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printVectorWDV (double *vector_) {\n",
        "\tfor (int indx = 0; indx < VECTOR_SIZE; indx++) {\n",
        "\t\tprintf(\"%lf \", vector_[indx]);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMinElem (long long *vector_) {\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] > vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findMaxElem (long long *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tif (vector_[firstElemIndx] < vector_[secondElemIndx]) {\n",
        "\t\t\t\tvector_[firstElemIndx] = vector_[secondElemIndx];\n",
        "\t\t\t}\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\t\n",
        "}\n",
        "\n",
        "__global__ void findMean (double *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tvector_[firstElemIndx] += vector_[secondElemIndx];\t\t\t\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "\tvector_[0] = vector_[0] / (double) VECTOR_SIZE;\n",
        "}\n",
        "\n",
        "__global__ void findSum (long long *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tvector_[firstElemIndx] += vector_[secondElemIndx];\t\t\t\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findSumVar (double *vector_) {\n",
        "\t\n",
        "\tint threadId = threadIdx.x;\n",
        "\tlong long stepSize = 1;\n",
        "\tint numberOfThreads = blockDim.x;\n",
        "\twhile (numberOfThreads > 0) {\n",
        "\t\tif (threadId < numberOfThreads) {\n",
        "\t\t\tint firstElemIndx = threadId * stepSize * 2;\n",
        "\t\t\tint secondElemIndx = firstElemIndx + stepSize;\n",
        "\t\t\tvector_[firstElemIndx] += vector_[secondElemIndx];\t\t\t\t\t\t\n",
        "\t\t}\n",
        "\t\tstepSize = stepSize * 2;\n",
        "\t\tnumberOfThreads = numberOfThreads / 2;\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void findVariance (double *vector_, double mean) {\n",
        "  \n",
        "  int threadId = threadIdx.x;\n",
        "  //printf(\"\\nthreaad : %d, vector_[threadid] : %lf\", threadId, vector_[threadId]);\n",
        "  vector_[threadId] = pow((vector_[threadId] - mean), 2);\n",
        "}\n",
        "\n",
        "int main (void) {\n",
        "\t{\n",
        "\t//program for finding minimum element from input vector\n",
        "\tlong long *hostVector, resultMinElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMinElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMinElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe minimum element in given vector : %lld\", resultMinElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding maximum element from input vector\n",
        "\n",
        "\tlong long *hostVector, resultMaxElem;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMaxElem<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMaxElem, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nInput Vector : \");\n",
        "\tprintVector(hostVector);\n",
        "\tprintf(\"\\nThe maximum element in given vector : %lld\", resultMaxElem);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding mean from input vector\n",
        "\n",
        "\tdouble *hostVector;\n",
        "\tdouble resultMean;\n",
        "\tdouble *deviceVector;\n",
        "\tdouble memorySize = VECTOR_SIZE * sizeof(double);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (double *)malloc(memorySize); \n",
        "\tfillVectorWDV(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMean<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMean, deviceVector, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nThe mean of the given vector : %lf\", resultMean);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding sum of all elements from input vector\n",
        "\n",
        "\tlong long *hostVector, resultSum;\n",
        "\tlong long *deviceVector;\n",
        "\tlong long memorySize = VECTOR_SIZE * sizeof(long long);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (long long *)malloc(memorySize); \n",
        "\tfillVector(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindSum<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultSum, deviceVector, sizeof(long long), cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\tprintf(\"\\nThe summation of all the elements in given vector : %lld\", resultSum);\n",
        "\t}\n",
        "\t{\n",
        "\t//program for finding standard deviation of elements from input vector\n",
        "\t//first find mean and then substract it from each element parallelly\n",
        "\n",
        "\t//program for finding mean from input vector\n",
        "\n",
        "\tdouble *hostVector;\n",
        "\tdouble resultMean;\n",
        "\tdouble *deviceVector;\n",
        "\tdouble memorySize = VECTOR_SIZE * sizeof(double);\n",
        "\t\n",
        "\t// Allocate space for host vectors A and insert input values\n",
        "    hostVector = (double *)malloc(memorySize); \n",
        "\tfillVectorWDV(hostVector);\n",
        "\t\n",
        "\t// Allocate space for device vectors A\n",
        "    cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\t\n",
        "\tdim3 blocksPerGrid(1, 1, 1);\n",
        "\t//by creating single block with half of the size of vector threads.\n",
        "\tdim3 threadsPerBlock(VECTOR_SIZE / 2, 1, 1);\n",
        "\tfindMean<<<blocksPerGrid, threadsPerBlock>>>(deviceVector);\n",
        "\t\n",
        "\t// Copy result back to host result variable \n",
        "    cudaMemcpy(&resultMean, deviceVector, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(deviceVector);\n",
        "\t\n",
        "\t//again,...\n",
        "\t// Allocate space for device vectors A\n",
        "  cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\tdouble *diffSumSqrVector;\n",
        "\tdiffSumSqrVector = (double *)malloc(memorySize); \n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, hostVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\tfindVariance<<<1, VECTOR_SIZE>>>(deviceVector, resultMean);\n",
        "\t//diffSumSqrVector stores (x(i) - xmean)^2 at each index, further we have to sum up aall and divide with VECTOR_SIZE to get variance.\n",
        "  cudaMemcpy(diffSumSqrVector, deviceVector, memorySize, cudaMemcpyDeviceToHost);\n",
        "  cudaFree(deviceVector);\n",
        "\n",
        "  double resultVarSum;\n",
        "  //again,...\n",
        "\t// Allocate space for device vectors A\n",
        "  cudaMalloc((void **)&deviceVector, memorySize);\n",
        "\t\n",
        "\t// Copy vector data from host to device\n",
        "    cudaMemcpy(deviceVector, diffSumSqrVector, memorySize, cudaMemcpyHostToDevice);\n",
        "\t\n",
        "\tfindSumVar<<<1, VECTOR_SIZE>>>(deviceVector);\n",
        "  // Copy result back to host result variable \n",
        "  cudaMemcpy(&resultVarSum, deviceVector, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "  cudaFree(deviceVector);\n",
        "\n",
        "  double variance = resultVarSum / (double) (VECTOR_SIZE - 1);\n",
        "\n",
        "  printf(\"\\nThe Variance of the elements in given vector : %lf\", variance);\n",
        "\n",
        "  double standardDeviation = sqrt(variance);\n",
        "\n",
        "  printf(\"\\nThe Standard Deviation of the elements in given vector : %lf\", standardDeviation);\n",
        "\n",
        "\t}\n",
        "  \treturn 0;\n",
        "}"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Vector : 1 2 3 4 5 6 7 8 \n",
            "The minimum element in given vector : 1\n",
            "Input Vector : 1 2 3 4 5 6 7 8 \n",
            "The maximum element in given vector : 8\n",
            "The mean of the given vector : 4.500000\n",
            "The summation of all the elements in given vector : 36\n",
            "The Variance of the elements in given vector : 6.000000\n",
            "The Standard Deviation of the elements in given vector : 2.449490\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}